{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a597164f-9392-481c-bdf7-7f7bec7562b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "# import library\n",
    "from scipy.stats import chi2_contingency\n",
    "from itertools import combinations\n",
    "# split test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "# sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "# scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# import lfeature selection ibrary & functions\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, VarianceThreshold, mutual_info_classif\n",
    "\n",
    "# import libraries for BayesianO ptimize\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "# set seed\n",
    "RANDOM_STATE = 1776\n",
    "\n",
    "def test():\n",
    "    print(\"123\")\n",
    "\n",
    "\n",
    "def percentageNull(datadf):\n",
    "    \"\"\"\n",
    "    This function calculates the percentage of missing values (NaN) for each column in a DataFrame \n",
    "    and returns those columns that contain any missing values, along with their corresponding NaN \n",
    "    count and percentage.\n",
    "    \"\"\"\n",
    "    # calculate the percentage of non-null values for each column\n",
    "    per_calc = pd.DataFrame(100 - (datadf.count() / len(datadf) * 100))\n",
    "    \n",
    "    # rename columns name\n",
    "    per_calc.rename(columns={0: 'percentage'}, inplace=True)\n",
    "\n",
    "    # add counter\n",
    "    per_calc['NaNCount'] = datadf.isna().sum()\n",
    "    \n",
    "    # sort\n",
    "    per_calc.sort_values(by='percentage', inplace=True, ascending=False)\n",
    "\n",
    "    # \n",
    "    NanReturn = per_calc[per_calc.NaNCount != 0]\n",
    "    \n",
    "    return NanReturn\n",
    "\n",
    "\n",
    "def DefinitionSearch(datadic, col, flag=False):\n",
    "    \"\"\"\n",
    "    This function is designed to search for a given column name (col) in a DataFrame (datadic) \n",
    "    based on the featureName column. It uses regular expression (regex) to perform a case-insensitive \n",
    "    search and returns a subset of the DataFrame or a list of feature names, depending on the flag parameter.\n",
    "    \"\"\"\n",
    "    # initialize variable\n",
    "    parm =  \"r'(?i)\" + col + \"'\" # regex search using ignore case sensitivity\n",
    "    parm = eval(parm)\n",
    "    # display\n",
    "    df_str = datadic.loc[:,['featureName','desc', 'dataType', 'labelSAS', 'COMMENT', 'Information']][datadic.featureName.str.contains(parm)]\n",
    "\n",
    "    if flag:\n",
    "        feature = datadic.featureName[datadic.featureName.str.contains(parm)].tolist()\n",
    "        return feature\n",
    "    else:\n",
    "        return df_str\n",
    "    \n",
    "    \n",
    "def removeColumn(datadf, col):\n",
    "    \"\"\"\n",
    "    Remove unwanted columns\n",
    "    \"\"\"\n",
    "    # display removed feature(s)\n",
    "    print(f\"\\nRemoved Features:{col}\\n\")\n",
    "    # display shape of DataFrame\n",
    "    print(f\"Total rows before: {datadf.shape[0]:,} & columns: {datadf.shape[1]:,}\")\n",
    "    \n",
    "    # remove column\n",
    "    datadf.drop(columns=col, axis=1, inplace=True)\n",
    "\n",
    "    # reset index in place\n",
    "    datadf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # display shape of DataFrame\n",
    "    print(f\"Total rows after: {datadf.shape[0]:,} & columns: {datadf.shape[1]:,}\")\n",
    "\n",
    "    return datadf\n",
    "\n",
    "\n",
    "def removeRowUsingMask(datadf, removeColLst, colstr):\n",
    "    # boolean mask\n",
    "    mask = ~datadf[colstr].isin(removeColLst)\n",
    "    \n",
    "    # apply the mask to keep only rows where 'removeColLst'\n",
    "    datadf = datadf[mask]\n",
    "    \n",
    "    # reset the index if needed\n",
    "    datadf = datadf.reset_index(drop=True)\n",
    "\n",
    "    # disply row removed msg\n",
    "    print(f\"Remove row(s) from df_{colstr} DataFrame.\")\n",
    "\n",
    "    return datadf\n",
    "\n",
    "    \n",
    "def updateDataDict(datadic, remove, col=\"COMMENT\"):\n",
    "    \"\"\"\n",
    "    Maintain data dictionary\n",
    "    \"\"\"\n",
    "    # update data dictionary\n",
    "    idx = datadic[datadic.featureName.isin(remove)].index\n",
    "    # append to exiting data\n",
    "    datadic.loc[idx,col] = \"**REMOVED 6** - \" + datadic[col]\n",
    "\n",
    "    # disply update msg\n",
    "    print(f\"Data Dictionary Updated.\")\n",
    "\n",
    "    return datadic\n",
    "\n",
    "\n",
    "def removeHouseKeeping(data, removeColLst, dataBool, dataOrdinal, dataNominal, dataNumeric):\n",
    "    \"\"\"\n",
    "    Run helper fuction for house keeping\n",
    "    \"\"\"\n",
    "    # remove DataFrame data (house keeping)\n",
    "    dataBool = removeRowUsingMask(dataBool, removeColLst, colstr='boolean')\n",
    "    dataOrdinal = removeRowUsingMask(dataOrdinal, removeColLst, colstr='ordinal')\n",
    "    dataNominal = removeRowUsingMask(dataNominal, removeColLst, colstr='nominal')\n",
    "    dataNumeric = removeRowUsingMask(dataNumeric, removeColLst, colstr='numeric')\n",
    "    \n",
    "    # remove features\n",
    "    data = removeColumn(data, removeColLst)\n",
    "\n",
    "    return data, dataBool, dataOrdinal, dataNominal, dataNumeric\n",
    "\n",
    "\n",
    "def datatypeDF(data, display=True):\n",
    "    # initialize variables for all the column name per each datatype\n",
    "    boolCol = data.select_dtypes(include=['bool']).columns.tolist()\n",
    "    catCol = data.select_dtypes(include=['category']).columns.tolist()\n",
    "    objCol = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    numCol = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    if display:\n",
    "        # display feature counts\n",
    "        print('Total Data feature count: ', df.shape[1])\n",
    "        print(f\"\\nBoolean feature count: {len(boolCol)}\")\n",
    "        print(f\"Category feature count: {len(catCol)}\")\n",
    "        print(f\"Numeric feature count: {len(numCol)}\")\n",
    "        print(f\"Object feature count: {len(objCol)}\\n\")\n",
    "        print('Total feature count: ' ,len(boolCol) + len(catCol) + len(objCol) + len(numCol))\n",
    "    else:\n",
    "        return boolCol, catCol, objCol, numCol\n",
    "\n",
    "\n",
    "def addtionalInfo(data, lst):\n",
    "    # iterate\n",
    "    for val in lst:\n",
    "        # mode (first if multiple)\n",
    "        modeValue = data[val].mode()[0]\n",
    "        modePercentage = data[val].value_counts(normalize=True, dropna=False)[modeValue]\n",
    "        modeCount = data[val].value_counts()[modeValue]\n",
    "        unique = data[val].nunique(dropna=False)\n",
    "\n",
    "        # display\n",
    "        print(f\"**{val}** Unique: {unique} & Mode: {modeValue} & Occurrence Count: {modeCount:,} & Percentage Occurrence: {(modePercentage * 100):.2f}%\")\n",
    "\n",
    "\n",
    "def removeCatZeroCount(data):\n",
    "    \"\"\"\n",
    "    Remove category with no category values\n",
    "    \"\"\"\n",
    "    # iterate each categorical column\n",
    "    for column in data.select_dtypes(['category']).columns:\n",
    "        # get counts of each category\n",
    "        category_counts = data[column].value_counts()\n",
    "        \n",
    "        # remove categories with zero counts\n",
    "        categories_to_keep = category_counts[category_counts > 0].index\n",
    "        data[column] = data[column].cat.remove_categories([cat for cat in data[column].cat.categories if cat not in categories_to_keep])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def pairColsMultiIndependenceCat(data, catCol):\n",
    "    \"\"\"\n",
    "    Hypothesis testing using Chi-square statistic and calculating Cramer's V to \n",
    "    build consensus for all the categorical variables. \n",
    "    \"\"\"\n",
    "    # initialize variables\n",
    "    results = []\n",
    "    validCols = [col for col in catCol if col in data.columns]\n",
    "\n",
    "    # use combinations to get unique pairs of columns\n",
    "    for col1, col2 in combinations(validCols, 2):\n",
    "        # create a contingency table\n",
    "        contingencyTable = pd.crosstab(data[col1], data[col2])\n",
    "        chi2, p_value, _, _ = chi2_contingency(contingencyTable)\n",
    "        # total number of observations\n",
    "        n = contingencyTable.values.sum()\n",
    "        # get the number of categories in each variable (rows and columns)\n",
    "        r, k = contingencyTable.shape\n",
    "        min_dim = min(r-1, k-1)\n",
    "        \n",
    "        # handle division by zero\n",
    "        if n * min_dim == 0:\n",
    "            cramer_v = np.nan\n",
    "        else:\n",
    "            cramer_v = np.sqrt(chi2 / (n * min_dim))\n",
    "        \n",
    "        results.append({\n",
    "            'column1': col1,\n",
    "            'column2': col2,\n",
    "            'chi2': chi2,\n",
    "            'p_value': p_value,\n",
    "            'cramer_v': cramer_v\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values(by='cramer_v', ascending=False)\n",
    "    \n",
    "    \n",
    "def testIndependenceCat(data, cat1, cat2, flag=False):\n",
    "    \"\"\"\n",
    "    Hypothesis testing using Ch-square statistic and calculating Cramer's V to \n",
    "    build consensus for two categorical variables.\n",
    "    \"\"\"\n",
    "    # create a contingency table\n",
    "    contingencyTable = pd.crosstab(data[cat1], data[cat2])\n",
    "    # perform Chi-square test\n",
    "    chi2, p_value, _, _ = chi2_contingency(contingencyTable)\n",
    "    \n",
    "    # total number of observations\n",
    "    n = contingencyTable.sum().sum()\n",
    "    # get the number of categories in each variable (rows and columns)\n",
    "    r, k = contingencyTable.shape\n",
    "    # calculate Cramer's V\n",
    "    cramer_v = np.sqrt(chi2 / (n * min(k-1, r-1)))\n",
    "\n",
    "    # display\n",
    "    print(f\"Test of Independence for Catergorical Variables: {cat1} & {cat2}\")\n",
    "    print(f\"Chi-square statistic: {chi2:,.2f}\")\n",
    "    print(f\"p-value: {p_value:,.4f}\")\n",
    "    print(f\"Cramer's V: {cramer_v:,.4f}\")\n",
    "\n",
    "    if flag:\n",
    "        return contingencyTable\n",
    "\n",
    "\n",
    "def classifier_metrics(model, Xdata, ydata, flag = None):\n",
    "    \"\"\"\n",
    "    Classfication metric for Project incldues \n",
    "    Model metrics & Confusion Matrix.\n",
    "    \"\"\"\n",
    "    # predictions\n",
    "    pred = model.predict(Xdata)\n",
    "    \n",
    "    # create confusion matrix\n",
    "    cm = metrics.confusion_matrix(ydata, pred, labels=model.classes_)\n",
    "    \n",
    "    # initialize variable\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    Spec = TN / (TN + FP)\n",
    "    Recall = TP / (TP + FN)\n",
    "    Acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "    if (TP + FP) == 0:\n",
    "        Prec = 0  # Set precision to 0 when denominator is 0\n",
    "    else:\n",
    "        Prec = TP / (TP + FP)\n",
    "    \n",
    "    # Prec = TP / (TP + FP)\n",
    "    if (Prec + Recall) == 0:\n",
    "        F1Score = 0  # Set F1Score to 0 when denominator is 0\n",
    "    else:\n",
    "        F1Score = 2 * (Prec * Recall) / (Prec + Recall)\n",
    "    # F1Score = 2 * (Prec * Recall) / (Prec + Recall)\n",
    "    AvgPrec = metrics.average_precision_score(ydata,pred)\n",
    "        \n",
    "    # print msgs\n",
    "    if flag:\n",
    "        print(\"*\" * 5 + \" Classfication Metrics for Validation/Test:\")\n",
    "    else:\n",
    "        print(\"*\" * 5 + \" Classfication Metrics for Training:\")\n",
    "        \n",
    "    # classification report for more metrics\n",
    "    print(\"Classification Report:\\n\", metrics.classification_report(ydata, pred, zero_division=0))\n",
    "\n",
    "    # create the ConfusionMatrixDisplay with labels\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(cm, display_labels = model.classes_)\n",
    "\n",
    "    # plot the confusion matrix\n",
    "    cm_display.plot(cmap='Blues', values_format='d', colorbar=False)\n",
    "    \n",
    "    #\n",
    "    if flag:\n",
    "        cm_display.ax_.set_title(\"Validation/Test Confusion Matrix\")\n",
    "    else:\n",
    "        cm_display.ax_.set_title(\"Training Confusion Matrix\")\n",
    "\n",
    "    # remove grid from plot\n",
    "    plt.grid(False)\n",
    "    # plot\n",
    "    plt.show()\n",
    "    # spacing\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # calculate ROC curve and AUC\n",
    "    fpr, tpr, _ = metrics.roc_curve(ydata, pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    # plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    return Spec, Recall, Acc, Prec, F1Score, AvgPrec, roc_auc\n",
    "\n",
    "\n",
    "def stratified_grid(model, parameters, Xdata, ydata, nJobs=-1, nSplit=5, score = 'roc_auc', seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    Ten fold CV Stratified\n",
    "    \"\"\"\n",
    "    # instantiate Stratified K-Fold cross-validation takes into account the class distribution\n",
    "    cv = StratifiedKFold(n_splits=nSplit, shuffle=True, random_state=seed)\n",
    "\n",
    "    # perform GridSearchCV\n",
    "    GSC_estimator = GridSearchCV(model, parameters, scoring=score, cv=cv, n_jobs=nJobs)\n",
    "\n",
    "    # evaluate a score by cross-validation\n",
    "    scores = cross_val_score(GSC_estimator, X=Xdata, y=ydata, scoring=score, cv=cv, n_jobs=nJobs)\n",
    "\n",
    "    # print average accuracy score CV with standard deviation\n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "    # fit model\n",
    "    fit = GSC_estimator.fit(Xdata, ydata)\n",
    "    \n",
    "    return fit\n",
    "\n",
    "\n",
    "def plotFeatureImportance(model, Xdata, figsize=(30,30)):\n",
    "    \"\"\"\n",
    "    Plot feature importance from the model\n",
    "    Order List & Bar Plot of Importance\n",
    "    \"\"\"\n",
    "    # create dataframe\n",
    "    data = pd.DataFrame(model.feature_importances_ * 100, index=Xdata.columns, columns=[\"% Feature Importance\"])\n",
    "    # print(data.sort_values(\"% Feature Importance\", axis=0, ascending=False))\n",
    "    # bar plot\n",
    "    plt.figure(figsize=figsize)\n",
    "    # create a bar plot using Seaborn\n",
    "    ax = sns.barplot(data=data, y=data.index, x = data['% Feature Importance'], orient= 'h')\n",
    "    ax.set_title(\"Feature Importance Bar Plot\", fontsize = 15)\n",
    "    # add a grid to the x-axis/\n",
    "    plt.grid(axis='x', linestyle='--')\n",
    "    plt.show()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def metricsClassfication(Algorithm, Model, Desc, Type, S, R, A, P, F, AP, Auc):\n",
    "    \"\"\"\n",
    "    Pass Classfication metrics and Model Information\n",
    "    \"\"\"\n",
    "    # initialize DataFrame\n",
    "    data = pd.DataFrame(columns=['Algorithm', 'Model', 'Description', 'DataType', 'Accuracy', 'RecallSensitivity','F1Score', 'AveragePrecision', 'Precision','Specificity', 'ROC_AUC_Score'])\n",
    "    # write to DataFrame\n",
    "    data.loc[len(data)] = [Algorithm, Model, Desc, Type, A, R, F, AP, P, S, Auc]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def metricsClassifier(model, Xdata, ydata, data, flag='Train'):\n",
    "    \"\"\"\n",
    "    The metricsClassifier function calculates classification metrics for a \n",
    "    given model and appends them to an existing DataFrame.\n",
    "    \"\"\"\n",
    "    # initialize variable\n",
    "    Type = flag\n",
    "    \n",
    "    if Type == 'Train':\n",
    "        Test = False\n",
    "    else:\n",
    "        Test = True\n",
    "    \n",
    "    # display report - training\n",
    "    S, R, A, P, F, AP, Auc = classifier_metrics(model, Xdata, ydata, Test)\n",
    "        \n",
    "    # add to DataFrame\n",
    "    df_metrics = metricsClassfication(Algorithm, Model, Desc, Type, S, R, A, P, F, AP, Auc)\n",
    "    \n",
    "    # concat two dataframes\n",
    "    data = pd.concat([data, df_metrics], ignore_index=True)\n",
    "    \n",
    "    # reset the index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def corrCols(df, threshold=0.9):\n",
    "    \"\"\"\n",
    "    This function is designed to identify pairs of features that are highly correlated in a dataset. \n",
    "    It calculates the correlation matrix of numerical columns and identifies pairs of features where \n",
    "    the absolute correlation is greater than a given threshold (default is 0.9).\n",
    "    \"\"\"\n",
    "    # initilaize variable\n",
    "    feature = list()\n",
    "    # calculate the correlation matrix\n",
    "    correlation_matrix = df.select_dtypes(exclude='object').corr()\n",
    "    \n",
    "    # get the number of features\n",
    "    num_features = correlation_matrix.shape[0]\n",
    "    \n",
    "    # iterate over the upper triangular part of the matrix\n",
    "    for i in range(num_features):\n",
    "        for j in range(i+1, num_features):\n",
    "            feature1 = correlation_matrix.index[i]\n",
    "            feature2 = correlation_matrix.columns[j]\n",
    "            correlation = correlation_matrix.iloc[i, j]\n",
    "            if abs(correlation) > threshold:\n",
    "                feature.append(feature2)\n",
    "                print(f\"Correlation between {feature1} and {feature2}: {correlation:.3f}\")\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "def EncodeDummyTrainValTest(data, labelTxt, nominalColumns, seed):\n",
    "    \"\"\"\n",
    "    This function performs dummy encoding on nominal columns, splits the dataset into training, \n",
    "    validation, and test sets, and returns the processed datasets. It ensures that the label column \n",
    "    is excluded from the nominal columns to prevent encoding the target variable.\n",
    "    \"\"\"\n",
    "    # remove label column from nominalColumns if it exists\n",
    "    if labelTxt in nominalColumns:\n",
    "        # remove label\n",
    "        nominalColumns.remove(labelTxt)\n",
    "\n",
    "    # dummy Encoding\n",
    "    df_encoded = pd.get_dummies(data, columns=nominalColumns, drop_first=True)\n",
    "\n",
    "    # entire features\n",
    "    X = df_encoded.drop(labelTxt, axis=1)\n",
    "    y = df_encoded[labelTxt]\n",
    "    \n",
    "    # split the dataset into 80% training and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    \n",
    "    # split train data into validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train)\n",
    "    \n",
    "    # display shape\n",
    "    print(f\"Training Dependent Shape: {X_train.shape} & Label Shape: {y_train.shape}\")\n",
    "    print(f\"Validation Dependent Shape: {X_val.shape} & Label Shape: {y_val.shape}\")\n",
    "    print(f\"Testing Dependent Shape: {X_test.shape} & Label Shape: {y_test.shape}\")\n",
    "\n",
    "    return  X, y, X_train, X_test, X_val, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def EncodeDummyScaleAllTrainValTest(data, labelTxt, nominalColumns, flag=True, seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    This function prepares a dataset for machine learning by performing dummy encoding on nominal columns, \n",
    "    scaling all features, and splitting the data into training, validation, and test sets. It can return the \n",
    "    scaled features as either numpy arrays or pandas DataFrames, based on the flag parameter.\n",
    "    \"\"\"\n",
    "    # remove label column from nominalColumns if it exists\n",
    "    if labelTxt in nominalColumns:\n",
    "        # remove label\n",
    "        nominalColumns.remove(labelTxt)\n",
    "\n",
    "    # dummy Encoding\n",
    "    df_encoded = pd.get_dummies(data, columns=nominalColumns, drop_first=True)\n",
    "\n",
    "    # entire features\n",
    "    X = df_encoded.drop(labelTxt, axis=1)\n",
    "    y = df_encoded[labelTxt]\n",
    "    \n",
    "    # split the dataset into 80% training and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    \n",
    "    # split train data into validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train)\n",
    "\n",
    "    # initialize scaling\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # fit model\n",
    "    fit = scaler.fit(X_train)\n",
    "\n",
    "    # transform\n",
    "    X_train = fit.transform(X_train)\n",
    "    X_val = fit.transform(X_val)\n",
    "    X_test = fit.transform(X_test)\n",
    "\n",
    "    if flag:\n",
    "        # convert to dataframe\n",
    "        X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "        X_val = pd.DataFrame(X_val, columns=X.columns)\n",
    "        X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "    \n",
    "    # display shape\n",
    "    print(f\"Training Dependent Shape: {X_train.shape} & Label Shape: {y_train.shape}\")\n",
    "    print(f\"Validation Dependent Shape: {X_val.shape} & Label Shape: {y_val.shape}\")\n",
    "    print(f\"Testing Dependent Shape: {X_test.shape} & Label Shape: {y_test.shape}\")\n",
    "\n",
    "    return  X, y, X_train, X_test, X_val, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def EncodeDummyScaleTrainValTest(Xdata, ydata, nominalColumns, numericColumns, seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    This function preprocesses a dataset for machine learning by encoding nominal variables, scaling numeric features, \n",
    "    and splitting the dataset into training, validation, and test sets. It ensures all steps, from encoding to scaling,\n",
    "     are applied consistently and provides stratified sampling based on a specified target class.\n",
    "    \"\"\"\n",
    "    # dummy Encoding\n",
    "    df_encoded = pd.get_dummies(Xdata, columns=nominalColumns, drop_first=True)\n",
    "    \n",
    "    # split the dataset into 80% training and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_encoded, ydata, test_size=0.2, random_state=seed, stratify=y['status'])\n",
    "    \n",
    "    # split train data into validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train['status'])\n",
    "\n",
    "    # initialize scaling\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # fit model\n",
    "    fit = scaler.fit(X_train[numericColumns])\n",
    "\n",
    "    # transform\n",
    "    X_train[numericColumns] = fit.transform(X_train[numericColumns])\n",
    "    X_val[numericColumns] = fit.transform(X_val[numericColumns])\n",
    "    X_test[numericColumns] = fit.transform(X_test[numericColumns])\n",
    "    \n",
    "    # display shape\n",
    "    print(f\"Training Dependent Shape: {X_train.shape} & Label Shape: {y_train.shape}\")\n",
    "    print(f\"Validation Dependent Shape: {X_val.shape} & Label Shape: {y_val.shape}\")\n",
    "    print(f\"Testing Dependent Shape: {X_test.shape} & Label Shape: {y_test.shape}\")\n",
    "\n",
    "    return  X, y, X_train, X_test, X_val, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "def selectKClassif(Xdata, ydata, K='all', function='f_classif'):\n",
    "    \"\"\"\n",
    "    This function selects the most relevant features for classification tasks using statistical tests provided \n",
    "    by SelectKBest and removes constant features from the dataset. It also returns detailed information on the \n",
    "    chosen features, including their scores and p-values.\n",
    "    \"\"\"\n",
    "    # remove constant features\n",
    "    constanFilter = VarianceThreshold(threshold=0)  # removes features with zero variance\n",
    "    X_data = constanFilter.fit_transform(Xdata)\n",
    "\n",
    "    # update feature names after removing constant features\n",
    "    remaining_feature_names = Xdata.columns[constanFilter.get_support(indices=True)]\n",
    "    \n",
    "    # Step 3: Apply SelectKBest with F-classif\n",
    "    selector = SelectKBest(score_func=eval(function), k=K)\n",
    "    X_new = selector.fit_transform(X_data, ydata)\n",
    "\n",
    "    # update feature names to reflect remaining, selected features\n",
    "    selected_List = [remaining_feature_names[i] for i in selector.get_support(indices=True)]\n",
    "    \n",
    "    # create a DataFrame with selected features and their F-scores\n",
    "    feature_scores = selector.scores_\n",
    "\n",
    "    # access the p-values\n",
    "    p_values = selector.pvalues_\n",
    "\n",
    "    # create DataFrame\n",
    "    feature_scores_df = pd.DataFrame({\n",
    "        'Feature': remaining_feature_names,\n",
    "        'Score': feature_scores,\n",
    "        'p_value': p_values\n",
    "    }).sort_values(by='Score', ascending=False)\n",
    "\n",
    "    # get ONLY selected Features\n",
    "    DF_selected = feature_scores_df[feature_scores_df.Feature.isin(selected_List)]\n",
    "    \n",
    "    # retrun\n",
    "    return DF_selected\n",
    "\n",
    "\n",
    "def getColumnName(data):\n",
    "    \"\"\"\n",
    "    This function identifies and processes feature names from a dataset that contains a specific substring (_U). \n",
    "    It extracts and returns the base feature names before the (_U) substring.\n",
    "    \"\"\"\n",
    "    # get features with Unknown Category\n",
    "    features = data.Feature[data['Feature'].str.contains('_U')].to_list()\n",
    "    \n",
    "    # extract the feature name up to (but not including) '_U'\n",
    "    removeFeatures = [re.search(r'^(.*?)_U', feature).group(1) if '_U' in feature else feature for feature in features]\n",
    "    \n",
    "    # display\n",
    "    print(removeFeatures)\n",
    "    \n",
    "    # return\n",
    "    return removeFeatures\n",
    "\n",
    "\n",
    "def BayesianOptimize(model, Xdata, ydata, search_space, custom_scorer,  nJobs=-1,  nIter=64, nSplit=10, seed=RANDOM_STATE):\n",
    "    \"\"\"\n",
    "    This function performs Bayesian Optimization to fine-tune hyperparameters for a given machine learning model. \n",
    "    It uses BayesSearchCV from scikit-optimize to search for the optimal combination of parameters over a specified \n",
    "    search space, leveraging a custom scoring metric and StratifiedKFold cross-validation.\n",
    "    \"\"\"\n",
    "    # instantiate Stratified K-Fold cross-validation takes into account the class distribution\n",
    "    kfold = StratifiedKFold(n_splits=nSplit, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # perform Bayesian Optimization with the custom scorer\n",
    "    opt = BayesSearchCV(estimator=model, search_spaces=search_space, n_iter=nIter, cv=kfold, n_jobs=-nJobs, scoring=custom_scorer)\n",
    "    BayesianOpt = opt.fit(Xdata, ydata)\n",
    "    \n",
    "    # best model\n",
    "    Bestmodel = BayesianOpt.best_estimator_\n",
    "    \n",
    "    # print the best parameters and best score\n",
    "    print(\"Best parameters found: \", BayesianOpt.best_params_)\n",
    "    print(\"Best accuracy score: \", BayesianOpt.best_score_)\n",
    "    \n",
    "    # display model\n",
    "    print(\"\\nCurrent Model Parameters:\")\n",
    "    print(\"\\n\", Bestmodel)\n",
    "\n",
    "    return Bestmodel\n",
    "\n",
    "\n",
    "# custom scoring function\n",
    "def class_specific_metrics(y_true, y_pred, target_class):\n",
    "    \"\"\"\n",
    "    Computes class-specific precision, recall, and F1 score for a given target class.\n",
    "    \"\"\"\n",
    "    precision = metrics.precision_score(y_true, y_pred, pos_label=target_class, zero_division=0)\n",
    "    recall = metrics.recall_score(y_true, y_pred, pos_label=target_class)\n",
    "    f1 = metrics.f1_score(y_true, y_pred, pos_label=target_class)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    }\n",
    "\n",
    "# using a specific Class 1\n",
    "target_class = 1\n",
    "custom_scorer = metrics.make_scorer(\n",
    "    lambda y_true, y_pred: class_specific_metrics(y_true, y_pred, target_class)[\"f1_score\"], \n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "\n",
    "def ClassificationMatric(Algorithm, Model, Desc, model, Xdata, ydata, Type, metricDF=None):\n",
    "    \"\"\"\n",
    "    This function evaluates a classification model's performance on a given dataset by calculating \n",
    "    key metrics such as specificity, sensitivity, accuracy, precision, F1 score, average precision, \n",
    "    and AUC (Area Under the Curve). It then compiles these metrics into a DataFrame, allowing users \n",
    "    to track performance results across different models.\n",
    "    \"\"\"\n",
    "    # determine training or validation/test\n",
    "    if Type.lower() == 'training':\n",
    "        flag = False\n",
    "    else:\n",
    "        flag = True\n",
    "\n",
    "    # capitalize\n",
    "    Type = Type.capitalize()\n",
    "        \n",
    "    # display report - training\n",
    "    Specificity, RecallSensitivity, Accuracy, Precision, F1, AveragePrecision, AUC = classifier_metrics(model, Xdata, ydata, flag=flag)\n",
    "    \n",
    "    # add to DataFrame\n",
    "    df_metrics = metricsClassfication(Algorithm, Model, Desc, Type, Specificity, RecallSensitivity, Accuracy, Precision, F1, AveragePrecision, AUC)\n",
    "\n",
    "    # check existing DataFrame\n",
    "    if metricDF is not None and not metricDF.empty:\n",
    "        # concat two dataframes\n",
    "        dfNew = pd.concat([metricDF, df_metrics], ignore_index=True)\n",
    "\n",
    "        # reset the index\n",
    "        dfNew.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        # copy first metrics dataframe\n",
    "        dfNew = df_metrics.copy()\n",
    "\n",
    "    return dfNew \n",
    "\n",
    "\n",
    "    def LogisticFeatureImportance(model, figsize=(8,10), fontsize=8):\n",
    "        \"\"\"\n",
    "        This function analyzes the importance of features in a logistic regression model by processing its \n",
    "        coefficients. It creates a DataFrame with each feature's name, coefficient, effect description, \n",
    "        odds ratio, percentage change in odds, and probability, including a barh plot.\n",
    "        \"\"\"\n",
    "        # determine feature information\n",
    "        feature_names = model.feature_names_in_\n",
    "        coefficients = model.coef_\n",
    "        \n",
    "        # create a DataFrame\n",
    "        LRcoeff_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': coefficients[0],\n",
    "            'Description': ['Decrease in the log-odds of the Positive Class' if x < 0 else 'Increase in the log-odds of the Positive Class' for x in coefficients[0]],\n",
    "            'Odd Ratio': np.exp(coefficients[0]),\n",
    "            'Percentage Change in Odds': (np.exp(coefficients[0]) - 1) * 100,\n",
    "            'Probability': np.exp(coefficients[0]) / (1 + np.exp(coefficients[0]))\n",
    "        })\n",
    "\n",
    "        # sort by Coefficient\n",
    "        LRcoeff_df = LRcoeff_df.sort_values(by='Coefficient')\n",
    "\n",
    "        # reset the index\n",
    "        LRcoeff_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # plot feature importance\n",
    "        LRcoeff_df.plot(kind='barh', x='Feature', y='Coefficient', figsize=figsize, title=\"Feature Importance (Logistic Regression)\", fontsize=fontsize)\n",
    "        plt.axvline(0, color='red', linestyle='-')\n",
    "        plt.xlabel(\"Absolute Coefficient Value\")\n",
    "        plt.ylabel(\"Features\")\n",
    "        plt.show()\n",
    "\n",
    "        return LRcoeff_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7214a378-a35d-4de1-8442-53d224db49ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
