{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449298f0-9a6e-40e1-bcb7-122b6a2c9eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 1.26.4\n",
      "Pandas Version: 2.2.3\n",
      "Seaborn Version: 0.13.2\n",
      "Matplotlib Version: 3.9.2\n",
      "Python Version: 3.9.20\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# seed\n",
    "RANDOM_STATE = 1776\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "# print versions\n",
    "print(\"Numpy Version: \" + np.__version__)\n",
    "print(\"Pandas Version: \" + pd.__version__)\n",
    "print(\"Seaborn Version: \" + sns.__version__)\n",
    "print(\"Matplotlib Version: \" + plt.matplotlib.__version__)\n",
    "print(\"Python Version: \" + python_version())\n",
    "\n",
    "# adjust pandas display options to max\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# adjust pandas display options to ensure full display of content\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66dfc36-0176-4dcf-9e39-4457a80d4fba",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2468686a-1c1b-417b-8491-87d340375767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full dataframe\n",
    "df = pd.read_pickle(\"../Data/CleanFullLabels.pkl\")\n",
    "\n",
    "# data dictionary\n",
    "df_dict = pd.read_pickle(\"../Data/FinalcolumnDefinition.pkl\")\n",
    "\n",
    "# data label\n",
    "df_label = pd.read_pickle(\"../Data/Label_Analysis.pkl\") \n",
    "\n",
    "# boolean\n",
    "df_bool = pd.read_pickle(\"../Data/colBoolean.pkl\")\n",
    "\n",
    "# nominal\n",
    "df_nominal = pd.read_pickle(\"../Data/colNominal.pkl\")\n",
    "\n",
    "# ordinal\n",
    "df_ordinal = pd.read_pickle(\"../Data/colOrdinal.pkl\")\n",
    "\n",
    "# numeric\n",
    "df_numeric = pd.read_pickle(\"../Data/colNumeric.pkl\")\n",
    "\n",
    "# checking for duplicated column name\n",
    "df.columns[df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0fc65-e0d5-45d6-86de-a5430fe4bf9a",
   "metadata": {},
   "source": [
    "#### Data Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b069bd6-aef3-4346-8a30-9d1f5843742f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Data file Shape: (14856, 181)\n",
      "Label(s) Data rows: 13\n",
      "Boolean(s) Data rows: 18\n",
      "Ordinal(s) Data rows: 34\n",
      "Nominal(s) Data rows: 99\n",
      "Numeric(s) Data rows: 30\n"
     ]
    }
   ],
   "source": [
    "# df DataFrame\n",
    "print(f\"Orginal Data file Shape: {df.shape}\")\n",
    "print(f\"Label(s) Data rows: {len(df_label)}\")\n",
    "print(f\"Boolean(s) Data rows: {len(df_bool)}\")\n",
    "print(f\"Ordinal(s) Data rows: {len(df_ordinal)}\")\n",
    "print(f\"Nominal(s) Data rows: {len(df_nominal)}\")\n",
    "print(f\"Numeric(s) Data rows: {len(df_numeric)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4dab8-4aa5-4d5a-b92f-06d74224b199",
   "metadata": {},
   "source": [
    "#### User Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b432150a-1bb9-44a6-bdef-163258845f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageNull(df):\n",
    "    \"\"\"\n",
    "    Calculate percentage of NaN & NaN count\n",
    "    \"\"\"\n",
    "    # calculate the percentage of non-null values for each column\n",
    "    per_calc = pd.DataFrame(100 - (df.count() / len(df) * 100))\n",
    "    \n",
    "    # rename columns name\n",
    "    per_calc.rename(columns={0: 'percentage'}, inplace=True)\n",
    "\n",
    "    # add counter\n",
    "    per_calc['NaNCount'] = df.isna().sum()\n",
    "    \n",
    "    # sort\n",
    "    per_calc.sort_values(by='percentage', inplace=True, ascending=False)\n",
    "\n",
    "    # \n",
    "    NanReturn = per_calc[per_calc.NaNCount != 0]\n",
    "    \n",
    "    return NanReturn\n",
    "\n",
    "\n",
    "def DefinitionSearch(datadic, col, flag=False):\n",
    "    # initialize variable\n",
    "    parm =  \"r'(?i)\" + col + \"'\" # regex search using ignore case sensitivity\n",
    "    parm = eval(parm)\n",
    "    # display\n",
    "    df_str = datadic.loc[:,['featureName','desc', 'dataType', 'labelSAS', 'COMMENT', 'Information']][datadic.featureName.str.contains(parm)]\n",
    "\n",
    "    if flag:\n",
    "        feature = datadic.featureName[datadic.featureName.str.contains(parm)].tolist()\n",
    "        return feature\n",
    "    else:\n",
    "        return df_str\n",
    "    \n",
    "    \n",
    "def removeColumn(data, col):\n",
    "    \"\"\"\n",
    "    Remove unwanted columns\n",
    "    \"\"\"\n",
    "    # display removed feature(s)\n",
    "    print(f\"\\nRemoved Features:{col}\\n\")\n",
    "    # display shape of DataFrame\n",
    "    print(f\"Total rows before: {data.shape[0]:,} & columns: {data.shape[1]:,}\")\n",
    "    \n",
    "    # remove column\n",
    "    data.drop(columns=col, axis=1, inplace=True)\n",
    "\n",
    "    # reset index in place\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # display shape of DataFrame\n",
    "    print(f\"Total rows after: {data.shape[0]:,} & columns: {data.shape[1]:,}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def removeRowUsingMask(data, removeColLst, colstr):\n",
    "    # boolean mask\n",
    "    mask = ~data[colstr].isin(removeColLst)\n",
    "    \n",
    "    # apply the mask to keep only rows where 'removeColLst'\n",
    "    data = data[mask]\n",
    "    \n",
    "    # reset the index if needed\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # disply row removed msg\n",
    "    print(f\"Remove row(s) from df_{colstr} DataFrame.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def removeHouseKeeping(data, removeColLst, dataBool, dataOrdinal, dataNominal, dataNumeric):\n",
    "    \"\"\"\n",
    "    Run helper fuction for house keeping\n",
    "    \"\"\"\n",
    "    # remove DataFrame data (house keeping)\n",
    "    dataBool = removeRowUsingMask(dataBool, removeColLst, colstr='boolean')\n",
    "    dataOrdinal = removeRowUsingMask(dataOrdinal, removeColLst, colstr='ordinal')\n",
    "    dataNominal = removeRowUsingMask(dataNominal, removeColLst, colstr='nominal')\n",
    "    dataNumeric = removeRowUsingMask(dataNumeric, removeColLst, colstr='numeric')\n",
    "    \n",
    "    # remove features\n",
    "    data = removeColumn(data, removeColLst)\n",
    "\n",
    "    return data, dataBool, dataOrdinal, dataNominal, dataNumeric\n",
    "\n",
    "\n",
    "def datatypeDF(data, display=True):\n",
    "    # initialize variables for all the column name per each datatype\n",
    "    boolCol = data.select_dtypes(include=['bool']).columns.tolist()\n",
    "    catCol = data.select_dtypes(include=['category']).columns.tolist()\n",
    "    objCol = data.select_dtypes(include=['object']).columns.tolist()\n",
    "    numCol = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    if display:\n",
    "        # display feature counts\n",
    "        print('Total Data feature count: ', df.shape[1])\n",
    "        print(f\"\\nBoolean feature count: {len(boolCol)}\")\n",
    "        print(f\"Category feature count: {len(catCol)}\")\n",
    "        print(f\"Numeric feature count: {len(numCol)}\")\n",
    "        print(f\"Object feature count: {len(objCol)}\\n\")\n",
    "        print('Total feature count: ' ,len(boolCol) + len(catCol) + len(objCol) + len(numCol))\n",
    "    else:\n",
    "        return boolCol, catCol, objCol, numCol\n",
    "\n",
    "\n",
    "def addtionalInfo(data, lst):\n",
    "    # iterate\n",
    "    for val in lst:\n",
    "        # mode (first if multiple)\n",
    "        modeValue = data[val].mode()[0]\n",
    "        modePercentage = data[val].value_counts(normalize=True, dropna=False)[modeValue]\n",
    "        modeCount = data[val].value_counts()[modeValue]\n",
    "        unique = data[val].nunique(dropna=False)\n",
    "\n",
    "        # display\n",
    "        print(f\"**{val}** Unique: {unique} & Mode: {modeValue} & Occurrence Count: {modeCount:,} & Percentage Occurrence: {(modePercentage * 100):.2f}%\")\n",
    "\n",
    "\n",
    "def removeCatZeroCount(data):\n",
    "    \"\"\"\n",
    "    Remove category with no category values\n",
    "    \"\"\"\n",
    "    # iterate each categorical column\n",
    "    for column in data.select_dtypes(['category']).columns:\n",
    "        # get counts of each category\n",
    "        category_counts = data[column].value_counts()\n",
    "        \n",
    "        # remove categories with zero counts\n",
    "        categories_to_keep = category_counts[category_counts > 0].index\n",
    "        data[column] = data[column].cat.remove_categories([cat for cat in data[column].cat.categories if cat not in categories_to_keep])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26397c21-8a5d-44d7-8e79-18995a263cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FollowUpFunctionalStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirwayDehiscencePostTransplant_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AcuteRejectionEpisode_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StrokePostTransplant_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PacemakerPostTransplant_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GraftFailed_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LastFollowupNumber_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TransplantStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TransplantSurvivalDay_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RecipientStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RejectionTreatmentWithinOneYear_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GraftStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LengthOfStay_CAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  label\n",
       "0          FollowUpFunctionalStatus_CAN\n",
       "1    AirwayDehiscencePostTransplant_CAN\n",
       "2             AcuteRejectionEpisode_CAN\n",
       "3              StrokePostTransplant_CAN\n",
       "4           PacemakerPostTransplant_CAN\n",
       "5                       GraftFailed_CAN\n",
       "6                LastFollowupNumber_CAN\n",
       "7                  TransplantStatus_CAN\n",
       "8             TransplantSurvivalDay_CAN\n",
       "9                   RecipientStatus_CAN\n",
       "10  RejectionTreatmentWithinOneYear_CAN\n",
       "11                      GraftStatus_CAN\n",
       "12                     LengthOfStay_CAN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e2b5cc-e336-411d-a374-5ac90f645989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove row(s) from df_boolean DataFrame.\n",
      "Remove row(s) from df_ordinal DataFrame.\n",
      "Remove row(s) from df_nominal DataFrame.\n",
      "Remove row(s) from df_numeric DataFrame.\n",
      "\n",
      "Removed Features:['FollowUpFunctionalStatus_CAN', 'AirwayDehiscencePostTransplant_CAN', 'AcuteRejectionEpisode_CAN', 'StrokePostTransplant_CAN', 'PacemakerPostTransplant_CAN', 'GraftFailed_CAN', 'LastFollowupNumber_CAN', 'TransplantStatus_CAN', 'RecipientStatus_CAN', 'RejectionTreatmentWithinOneYear_CAN', 'GraftStatus_CAN', 'LengthOfStay_CAN']\n",
      "\n",
      "Total rows before: 14,856 & columns: 181\n",
      "Total rows after: 14,856 & columns: 169\n"
     ]
    }
   ],
   "source": [
    "# select label for classification\n",
    "removeCol = df_label.label.to_list()\n",
    "\n",
    "# remove GraftFailed_CAN\n",
    "removeCol.remove('TransplantSurvivalDay_CAN')\n",
    "\n",
    "# remove unwanted features\n",
    "df, df_bool, df_ordinal, df_nominal, df_numeric = removeHouseKeeping(df, removeCol, df_bool, df_ordinal, df_nominal, df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb883af1-65c2-46bd-b86a-35c53e94c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Data file Shape: (14856, 169)\n",
      "Boolean(s) Data rows: 17\n",
      "Ordinal(s) Data rows: 34\n",
      "Nominal(s) Data rows: 89\n",
      "Numeric(s) Data rows: 29\n",
      "\n",
      "Total Length of Features: 169\n"
     ]
    }
   ],
   "source": [
    "# df DataFrame\n",
    "print(f\"Orginal Data file Shape: {df.shape}\")\n",
    "print(f\"Boolean(s) Data rows: {len(df_bool)}\")\n",
    "print(f\"Ordinal(s) Data rows: {len(df_ordinal)}\")\n",
    "print(f\"Nominal(s) Data rows: {len(df_nominal)}\")\n",
    "print(f\"Numeric(s) Data rows: {len(df_numeric)}\")\n",
    "print(\"\\nTotal Length of Features:\", len(df_bool) + len(df_ordinal) + len(df_nominal) + len(df_numeric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4146d669-3121-4d3c-93fd-920205a27d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features names to list\n",
    "boolCol = df_bool.boolean.to_list()\n",
    "nominalCol = df_nominal.nominal.to_list()\n",
    "ordinalCol = df_ordinal.ordinal.to_list()\n",
    "numericCol = df_numeric.numeric.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0797bbac-9750-439e-829b-472008acabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode columns\n",
    "columns = df_nominal.nominal.to_list()\n",
    "\n",
    "# remove label\n",
    "# columns.remove('TransplantSurvivalDay_CAN')\n",
    "\n",
    "# dummy Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11b921-3359-470f-873d-ef6c7d9e32c5",
   "metadata": {},
   "source": [
    "#### Split Testing & Validation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5e4b7d-7a68-4d7b-9510-175a893bf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# entire features\n",
    "X = df_encoded.drop('TransplantSurvivalDay_CAN', axis=1)\n",
    "y = df_encoded['TransplantSurvivalDay_CAN']\n",
    "\n",
    "# split the dataset into 80% training and 30% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "# split train data into validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391b7dc-dadf-4638-91be-ccd76a769ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RFSurvival",
   "language": "python",
   "name": "survival_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
