{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a00c39-2790-4090-8185-79cedb8f8aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1\n",
      "Numpy Version: 2.1.3\n",
      "Pandas Version: 2.2.3\n",
      "Seaborn Version: 0.13.2\n",
      "Matplotlib Version: 3.9.2\n",
      "Python Version: 3.11.10\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# seed\n",
    "RANDOM_STATE = 1776\n",
    "\n",
    "# set seaborn theme\n",
    "sns.set_theme()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import MinMax Scaler library\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# print versions\n",
    "print(\"PyTorch Version: \" + torch.__version__)\n",
    "print(\"Numpy Version: \" + np.__version__)\n",
    "print(\"Pandas Version: \" + pd.__version__)\n",
    "print(\"Seaborn Version: \" + sns.__version__)\n",
    "print(\"Matplotlib Version: \" + plt.matplotlib.__version__)\n",
    "print(\"Python Version: \" + python_version())\n",
    "\n",
    "# adjust pandas display options to max\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "# adjust pandas display options to ensure full display of content\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b89c01da-39bd-46e4-b190-d7f144850d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full dataframe\n",
    "df = pd.read_pickle(\"../Data/CleanFullLabelsML.pkl\")\n",
    "\n",
    "# data label\n",
    "df_label = pd.read_pickle(\"../Data/colLabelML.pkl\") \n",
    "\n",
    "# boolean\n",
    "df_bool = pd.read_pickle(\"../Data/colBooleanML.pkl\")\n",
    "\n",
    "# nominal\n",
    "df_nominal = pd.read_pickle(\"../Data/colNominalML.pkl\")\n",
    "\n",
    "# ordinal\n",
    "df_ordinal = pd.read_pickle(\"../Data/colOrdinalML.pkl\")\n",
    "\n",
    "# numeric\n",
    "df_numeric = pd.read_pickle(\"../Data/colNumericML.pkl\")\n",
    "\n",
    "# checking for duplicated column name\n",
    "df.columns[df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec2b85a-df72-4e08-af6e-a81dba3bcae8",
   "metadata": {},
   "source": [
    "### User function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e77ae6da-e46c-47ec-99e1-92fd6437690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentageNull(datadf):\n",
    "    \"\"\"\n",
    "    Calculate percentage of NaN & NaN count\n",
    "    \"\"\"\n",
    "    # calculate the percentage of non-null values for each column\n",
    "    per_calc = pd.DataFrame(100 - (datadf.count() / len(datadf) * 100))\n",
    "    \n",
    "    # rename columns name\n",
    "    per_calc.rename(columns={0: 'percentage'}, inplace=True)\n",
    "\n",
    "    # add counter\n",
    "    per_calc['NaNCount'] = datadf.isna().sum()\n",
    "    \n",
    "    # sort\n",
    "    per_calc.sort_values(by='percentage', inplace=True, ascending=False)\n",
    "\n",
    "    # \n",
    "    NanReturn = per_calc[per_calc.NaNCount != 0]\n",
    "    \n",
    "    return NanReturn\n",
    "    \n",
    "    \n",
    "def removeColumn(data, col):\n",
    "    \"\"\"\n",
    "    Remove unwanted columns\n",
    "    \"\"\"\n",
    "    # display removed feature(s)\n",
    "\n",
    "    print(f\"\\nRemoved Features:{col}\\n\")\n",
    "    # display shape of DataFrame\n",
    "    print(f\"Total rows before: {data.shape[0]:,} & columns: {data.shape[1]:,}\")\n",
    "    \n",
    "    # remove column\n",
    "    data.drop(columns=col, axis=1, inplace=True)\n",
    "\n",
    "    # reset index in place\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # display shape of DataFrame\n",
    "    print(f\"Total rows after: {data.shape[0]:,} & columns: {data.shape[1]:,}\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def removeRowUsingMask(data, removeColLst, colstr):\n",
    "    # boolean mask\n",
    "    mask = ~data[colstr].isin(removeColLst)\n",
    "    \n",
    "    # apply the mask to keep only rows where 'removeColLst'\n",
    "    data = data[mask]\n",
    "    \n",
    "    # reset the index if needed\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    # disply row removed msg\n",
    "    print(f\"Remove row(s) from df_{colstr} DataFrame.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def removeHouseKeeping(data, removeColLst, dataBool, dataOrdinal, dataNominal, dataNumeric, dataLabel):\n",
    "    \"\"\"\n",
    "    Run helper fuction for house keeping\n",
    "    \"\"\"\n",
    "    # remove DataFrame data (house keeping)\n",
    "    dataLabel = removeRowUsingMask(dataLabel, removeColLst, colstr='label')\n",
    "    dataBool = removeRowUsingMask(dataBool, removeColLst, colstr='boolean')\n",
    "    dataOrdinal = removeRowUsingMask(dataOrdinal, removeColLst, colstr='ordinal')\n",
    "    dataNominal = removeRowUsingMask(dataNominal, removeColLst, colstr='nominal')\n",
    "    dataNumeric = removeRowUsingMask(dataNumeric, removeColLst, colstr='numeric')\n",
    "    \n",
    "    # remove features\n",
    "    data = removeColumn(data, removeColLst)\n",
    "\n",
    "    return data, dataBool, dataOrdinal, dataNominal, dataNumeric, dataLabel\n",
    "\n",
    "\n",
    "def datatypeDF(data, databool, datanominal, dataordinal, datanumeric):    \n",
    "    # initialize variables for all the column name per each datatype\n",
    "    boolCol = databool.boolean.to_list()\n",
    "    nominalCol = datanominal.nominal.to_list()\n",
    "    ordinalCol = dataordinal.ordinal.to_list()\n",
    "    numericCol = datanumeric.numeric.to_list()\n",
    "\n",
    "    print('Total Data feature count: ', df.shape[1])\n",
    "    print(f\"\\nBoolean feature count: {len(boolCol)}\")\n",
    "    print(f\"Nominal feature count: {len(nominalCol)}\")\n",
    "    print(f\"Ordinal feature count: {len(ordinalCol)}\")\n",
    "    print(f\"Numeric feature count: {len(numericCol)}\")\n",
    "    print('\\nTotal feature count: ' ,len(boolCol) + len(nominalCol) + len(ordinalCol) + len(numericCol))\n",
    "\n",
    "    # return list for each type\n",
    "    return boolCol, nominalCol, ordinalCol, numericCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f24287-f666-40b5-bc55-907d774c9273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FollowUpFunctionalStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirwayDehiscencePostTransplant_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AcuteRejectionEpisode_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StrokePostTransplant_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PacemakerPostTransplant_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GraftFailed_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LastFollowupNumber_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TransplantStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TransplantSurvivalDay_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RecipientStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RejectionTreatmentWithinOneYear_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GraftStatus_CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LengthOfStay_CAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  label\n",
       "0          FollowUpFunctionalStatus_CAN\n",
       "1    AirwayDehiscencePostTransplant_CAN\n",
       "2             AcuteRejectionEpisode_CAN\n",
       "3              StrokePostTransplant_CAN\n",
       "4           PacemakerPostTransplant_CAN\n",
       "5                       GraftFailed_CAN\n",
       "6                LastFollowupNumber_CAN\n",
       "7                  TransplantStatus_CAN\n",
       "8             TransplantSurvivalDay_CAN\n",
       "9                   RecipientStatus_CAN\n",
       "10  RejectionTreatmentWithinOneYear_CAN\n",
       "11                      GraftStatus_CAN\n",
       "12                     LengthOfStay_CAN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display labels\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11da720-ed04-4620-a786-9d022a2f6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove row(s) from df_label DataFrame.\n",
      "Remove row(s) from df_boolean DataFrame.\n",
      "Remove row(s) from df_ordinal DataFrame.\n",
      "Remove row(s) from df_nominal DataFrame.\n",
      "Remove row(s) from df_numeric DataFrame.\n",
      "\n",
      "Removed Features:['FollowUpFunctionalStatus_CAN', 'AirwayDehiscencePostTransplant_CAN', 'AcuteRejectionEpisode_CAN', 'StrokePostTransplant_CAN', 'PacemakerPostTransplant_CAN', 'LastFollowupNumber_CAN', 'TransplantStatus_CAN', 'TransplantSurvivalDay_CAN', 'RecipientStatus_CAN', 'RejectionTreatmentWithinOneYear_CAN', 'GraftStatus_CAN', 'LengthOfStay_CAN']\n",
      "\n",
      "Total rows before: 14,856 & columns: 121\n",
      "Total rows after: 14,856 & columns: 109\n"
     ]
    }
   ],
   "source": [
    "# select label for classification\n",
    "removeCol = df_label.label.to_list()\n",
    "\n",
    "# remove GraftFailed_CAN\n",
    "removeCol.remove('GraftFailed_CAN')\n",
    "\n",
    "# remove unwanted features\n",
    "df, df_bool, df_ordinal, df_nominal, df_numeric, df_label = removeHouseKeeping(df, removeCol, df_bool, df_ordinal, df_nominal, df_numeric, df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63c0f31-8f04-4316-b0e5-ba6f42a68561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data feature count:  109\n",
      "\n",
      "Boolean feature count: 8\n",
      "Nominal feature count: 70\n",
      "Ordinal feature count: 15\n",
      "Numeric feature count: 16\n",
      "\n",
      "Total feature count:  109\n"
     ]
    }
   ],
   "source": [
    "# initialize list with feature names\n",
    "boolCol, nominalCol, ordinalCol, numericCol = datatypeDF(df, df_bool, df_nominal, df_ordinal, df_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a1f9d2-07a4-4c06-b4f2-9c6137e551eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# covert boolean features to integers\n",
    "df[boolCol] = df[boolCol].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe39a2d-37dd-42ce-a835-ed76c52ecc6f",
   "metadata": {},
   "source": [
    "#### Split Testing & Validation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24f1538-1956-4908-bccb-198f7ff633d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def EncodeDummyTrainValTest(data, labelTxt, nominalColumns, numericColumns, seed=RANDOM_STATE):\n",
    "\n",
    "    # remove label column from nominalColumns if it exists\n",
    "    if labelTxt in nominalColumns:\n",
    "        # remove label\n",
    "        nominalColumns.remove(labelTxt)\n",
    "\n",
    "    # dummy Encoding\n",
    "    df_encoded = pd.get_dummies(data, columns=nominalColumns, drop_first=True)\n",
    "\n",
    "    # entire features\n",
    "    X = df_encoded.drop(labelTxt, axis=1)\n",
    "    y = df_encoded[labelTxt]\n",
    "    \n",
    "    # split the dataset into 80% training and 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)\n",
    "    \n",
    "    # split train data into validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=seed, stratify=y_train)\n",
    "\n",
    "    # initialize scaling\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # fit model\n",
    "    fit = scaler.fit(X_train[numericColumns])\n",
    "\n",
    "    # transform\n",
    "    X_train[numericColumns] = fit.transform(X_train[numericColumns])\n",
    "    X_val[numericColumns] = fit.transform(X_val[numericColumns])\n",
    "    X_test[numericColumns] = fit.transform(X_test[numericColumns])\n",
    "    \n",
    "    # display shape\n",
    "    print(f\"Training Dependent Shape: {X_train.shape} & Label Shape: {y_train.shape}\")\n",
    "    print(f\"Validation Dependent Shape: {X_val.shape} & Label Shape: {y_val.shape}\")\n",
    "    print(f\"Testing Dependent Shape: {X_test.shape} & Label Shape: {y_test.shape}\")\n",
    "\n",
    "    return  X, y, X_train, X_test, X_val, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e2473-4150-4bfb-b429-dc4fdd9bdd7d",
   "metadata": {},
   "source": [
    "#### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178b679e-b8fc-4490-82b8-7791f68404cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dependent Shape: (9507, 204) & Label Shape: (9507,)\n",
      "Validation Dependent Shape: (2377, 204) & Label Shape: (2377,)\n",
      "Testing Dependent Shape: (2972, 204) & Label Shape: (2972,)\n"
     ]
    }
   ],
   "source": [
    "# split dataset\n",
    "X, y, X_train, X_test, X_val, y_train, y_val, y_test = EncodeDummyTrainValTest(df, 'GraftFailed_CAN', nominalCol, numericCol, RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7db46-482c-428e-b8ff-eb87ba36ed92",
   "metadata": {},
   "source": [
    "#### Convert to Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9a272b-8e5f-4c43-bf69-e4ec4655c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the column names of boolean columns in X_train & X_val & X_test\n",
    "bool_columns = X_train.select_dtypes(include='bool').columns\n",
    "X_train[bool_columns] = X_train[bool_columns].astype(int)\n",
    "\n",
    "bool_columns = X_val.select_dtypes(include='bool').columns\n",
    "X_val[bool_columns] = X_val[bool_columns].astype(int)\n",
    "\n",
    "bool_columns = X_test.select_dtypes(include='bool').columns\n",
    "X_test[bool_columns] = X_test[bool_columns].astype(int)\n",
    "\n",
    "# convert features (X) to PyTorch tensors\n",
    "X_train = torch.from_numpy(np.array(X_train)).float()\n",
    "X_val = torch.from_numpy(np.array(X_val)).float()\n",
    "X_test = torch.from_numpy(np.array(X_test)).float()\n",
    "\n",
    "# convert labels (y) to PyTorch tensors\n",
    "y_train = torch.from_numpy(np.array(y_train)).float()\n",
    "y_val = torch.from_numpy(np.array(y_val)).float()\n",
    "y_test = torch.from_numpy(np.array(y_test)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7c9e69-3dc1-4162-bb7a-72109e7881fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([9507, 204]), torch.Size([9507]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a260976-9992-4710-a295-6bc86f4d0939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "        # Calculate the output size after the convolutional layers\n",
    "        self._to_linear = None\n",
    "        self.convs(torch.randn(1, 1, 204))\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 128)\n",
    "        self.dropout_fc1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "        \n",
    "    def convs(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        \n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x.shape[1] * x.shape[2]\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout_fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return torch.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24e87e6d-1ec8-4302-accc-318660dd60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "# Check if MPS is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Create DataLoader for training and validation\n",
    "train_dataset = TensorDataset(X_train.unsqueeze(1), y_train)\n",
    "val_dataset = TensorDataset(X_val.unsqueeze(1), y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bff04a2-4e48-4602-bd0c-7fad65ea814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 204]), torch.Size([]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].shape, train_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0e6ce-c206-4eb6-bdba-fc22f8cfd5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = ConvNet1D().to(device)\n",
    "\n",
    "# get both classes\n",
    "num_positive = (y_train == 1).sum().item()\n",
    "num_negative = (y_train == 0).sum().item()\n",
    "\n",
    "# Calculate the positive weight\n",
    "pos_weight = torch.tensor([num_negative / num_positive]).to(device) \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "# criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=8, gamma=0.1)\n",
    "\n",
    "\n",
    "threshold = 0.2\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_outputs = []\n",
    "    train_labels = []\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch).squeeze()\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_outputs.append(outputs)\n",
    "        train_labels.append(y_batch)\n",
    "    \n",
    "    train_outputs = torch.cat(train_outputs)\n",
    "    train_labels = torch.cat(train_labels)\n",
    "    train_preds = (torch.sigmoid(train_outputs) > threshold).float()\n",
    "    train_accuracy = metrics.accuracy_score(train_labels.cpu(), train_preds.cpu())\n",
    "    train_f1 = metrics.f1_score(train_labels.cpu(), train_preds.cpu())\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_outputs = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            val_outputs.append(outputs)\n",
    "            val_labels.append(y_batch)\n",
    "    \n",
    "    val_outputs = torch.cat(val_outputs)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    val_loss = criterion(val_outputs, val_labels).item()\n",
    "    val_preds = (torch.sigmoid(val_outputs) > threshold).float()\n",
    "    val_accuracy = metrics.accuracy_score(val_labels.cpu(), val_preds.cpu())\n",
    "    val_f1 = metrics.f1_score(val_labels.cpu(), val_preds.cpu())\n",
    "    \n",
    "    # Get learning rate prior to scheduler step\n",
    "    last_lr = scheduler.get_last_lr()[0]\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "    curr_lr = scheduler.get_last_lr()[0]\n",
    "    # Display if learning rate changed\n",
    "    if last_lr != curr_lr:\n",
    "        print(f\"Learning Rate {last_lr} has been Updated to: {curr_lr}\")\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.5f}, Train Accuracy: {train_accuracy:.5f}, Train F1: {train_f1:.5f}, Val Loss: {val_loss:.5f}, Val Accuracy: {val_accuracy:.5f}, Val F1: {val_f1:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c417b-5a5a-4208-95f5-e9af4ccf2a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c67f70-9e87-45cc-90bb-330c6032e91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62146f4-7995-41c2-9027-41b2a2dd6069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28eeacbf-5715-4a5d-bf41-b0566ddb8fa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m---> 17\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTabularConvNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m, in \u001b[0;36mTabularConvNet.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv1d(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m32\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[43mn_features\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m4\u001b[39m), \u001b[38;5;241m64\u001b[39m)  \u001b[38;5;66;03m# Adjust based on conv output size\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_features' is not defined"
     ]
    }
   ],
   "source": [
    "class TabularConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TabularConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(32 * (n_features - 4), 64)  # Adjust based on conv output size\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = TabularConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c298d-ae69-498f-81b2-a0834fd864c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
